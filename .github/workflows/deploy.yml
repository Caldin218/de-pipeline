name: Deploy Airflow DAGs

on:
  push:
    branches:
      - main
    paths:
      - "airflow/dags/**"
      - "pipelines/**"
      - "configs/**"
      - "docker/**"
      - "docker-compose.yml"
      - ".env.example"
  workflow_dispatch:

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install flake8

      - name: Run flake8 lint
        run: |
          flake8 airflow/dags/ pipelines/ configs/
        continue-on-error: true

      - name: Debug files in repo
        run: |
          ls -R airflow/dags || true
          ls -R pipelines || true
          ls -R configs || true

      - name: Upload DAGs and configs to EC2 server
        uses: appleboy/scp-action@v0.1.7
        with:
          host: ${{ secrets.SERVER_HOST }}
          username: ${{ secrets.SERVER_USER }}
          key: ${{ secrets.SERVER_SSH_KEY }}
          source: "airflow/dags/*,pipelines/*,configs/*,docker-compose.yml"
          target: /home/${{ secrets.SERVER_USER }}/airflow-deploy/

      - name: Restart Airflow & sync files
        uses: appleboy/ssh-action@v0.1.10
        with:
          host: ${{ secrets.SERVER_HOST }}
          username: ${{ secrets.SERVER_USER }}
          key: ${{ secrets.SERVER_SSH_KEY }}
          script: |
            set -e
            cd /home/${{ secrets.SERVER_USER }}

            echo "ðŸ§¹ Sync DAGs and configs..."
            mkdir -p airflow/dags airflow/dags/pipelines airflow/configs
            cp -r airflow-deploy/airflow/dags/* airflow/dags/ || true
            cp -r airflow-deploy/pipelines/* airflow/dags/pipelines/ || true
            cp -r airflow-deploy/configs/* airflow/configs/ || true

            echo "ðŸ›  Generate .env from GitHub Secrets..."
            cd /home/${{ secrets.SERVER_USER }}/airflow-deploy
            cat > .env <<EOL
            AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
            AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
            AWS_REGION=${{ secrets.AWS_REGION }}
            S3_BUCKET=${{ secrets.S3_BUCKET }}
            SLACK_WEBHOOK_URL=${{ secrets.SLACK_WEBHOOK_URL }}
            AIRFLOW__SMTP__SMTP_HOST=${{ secrets.AIRFLOW__SMTP__SMTP_HOST }}
            AIRFLOW__SMTP__SMTP_STARTTLS=${{ secrets.AIRFLOW__SMTP__SMTP_STARTTLS }}
            AIRFLOW__SMTP__SMTP_SSL=${{ secrets.AIRFLOW__SMTP__SMTP_SSL }}
            AIRFLOW__SMTP__SMTP_USER=${{ secrets.AIRFLOW__SMTP__SMTP_USER }}
            AIRFLOW__SMTP__SMTP_PASSWORD=${{ secrets.AIRFLOW__SMTP__SMTP_PASSWORD }}
            AIRFLOW__SMTP__SMTP_PORT=${{ secrets.AIRFLOW__SMTP__SMTP_PORT }}
            AIRFLOW__SMTP__SMTP_MAIL_FROM=${{ secrets.AIRFLOW__SMTP__SMTP_MAIL_FROM }}
            EOL

            echo "ðŸ”„ Restarting Airflow..."
            docker-compose restart airflow-webserver airflow-scheduler

            echo "âœ… Deployment finished!"
