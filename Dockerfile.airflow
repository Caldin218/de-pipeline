FROM apache/airflow:2.8.1-python3.11

USER root
# Java + Spark
RUN apt-get update && \
    apt-get install -y openjdk-17-jdk curl && \
    rm -rf /var/lib/apt/lists/* && \
    curl -L https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz \
    | tar -xz -C /opt/ && \
    ln -s /opt/spark-3.5.0-bin-hadoop3 /opt/spark

ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH="${JAVA_HOME}/bin:/opt/spark/bin:${PATH}"

# Copy requirements
COPY requirements-airflow.txt /requirements.txt

# Đổi user trước khi cài pip
USER airflow
RUN pip install --no-cache-dir --no-deps -r /requirements.txt